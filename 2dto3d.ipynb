{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "VEHICLES:这取决于你感兴趣的车辆类型,例如,可以设为 [\"Car\", \"Van\", \"Truck\"]。\n",
    "\n",
    "BIN:可能的值可能在10到90之间,这取决于你需要多精细的方向划分。一个常用的值是30,即每个方向区间为12度。\n",
    "\n",
    "OVERLAP:这通常需要设置为0到1之间的一个较小值。可能的值可以是0.1。\n",
    "\n",
    "MAX_JIT:这取决于你希望有多大的随机边界框偏移。如果你的图像大小是224,那么可能的值可以是30。\n",
    "\n",
    "NORM_H, NORM_W:这需要根据你的模型的输入要求进行设置。常见的值可能是224,这是许多卷积神经网络的默认输入大小。\n",
    "\n",
    "label_dir, image_dir:这需要设置为你的标签文件和图像文件的实际存储路径。\n",
    "\n",
    "batch_size:这需要根据你的硬件资源和模型大小进行设置。一个常见的值可能是32,但如果你的模型非常大或者你的硬件资源有限,你可能需要选择一个更小的值。\n",
    "'''\n",
    "\n",
    "BIN, OVERLAP = 30, 0.1\n",
    "MAX_JIT = 30\n",
    "NORM_H, NORM_W = 224, 224\n",
    "VEHICLES = ['Car', 'Van', 'Truck', 'Pedestrian', 'Sitter', 'Cyclist', 'Tram', 'Misc']\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "label_dir = 'E:/Codespace/image-to-3d-bbox/data/image_to_train/data_object_label_2/training/label_2/'\n",
    "image_dir = 'E:/Codespace/image-to-3d-bbox/data/image_to_train/data_object_image_2/training/image_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from parameters import (BATCH_SIZE, BIN, MAX_JIT, NORM_H, NORM_W,\n",
    "                        OVERLAP, VEHICLES, image_dir, label_dir)\n",
    "\n",
    "\n",
    "def compute_anchors(angle):\n",
    "    anchors = []\n",
    "\n",
    "    spaceangle = 2*np.pi / BIN\n",
    "    l_index = int(angle/spaceangle)\n",
    "    r_index = l_index + 1\n",
    "\n",
    "    if (angle - l_index*spaceangle) < spaceangle/2 * (1 + OVERLAP/2):\n",
    "        anchors.append([l_index, angle - l_index*spaceangle])\n",
    "\n",
    "    if (r_index*spaceangle - angle) < spaceangle/2 * (1+OVERLAP/2):\n",
    "        anchors.append([r_index % BIN, angle - r_index*spaceangle])\n",
    "\n",
    "    return anchors\n",
    "\n",
    "\n",
    "def parse_annotation(label_dir, image_dir):\n",
    "    all_objs = []\n",
    "    dims_avg = {key: np.array([0, 0, 0]) for key in VEHICLES}\n",
    "    dims_cnt = {key: 0 for key in VEHICLES}\n",
    "\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        image_file = label_file.replace('txt', 'png')\n",
    "\n",
    "        for line in open(label_dir + label_file).readlines():\n",
    "            line = line.strip().split(' ')\n",
    "            truncated = np.abs(float(line[1]))\n",
    "            occluded = np.abs(float(line[2]))\n",
    "\n",
    "            if line[0] in VEHICLES and truncated < 0.1 and occluded < 0.1:\n",
    "                new_alpha = float(line[3]) + np.pi/2.\n",
    "                if new_alpha < 0:\n",
    "                    new_alpha = new_alpha + 2.*np.pi\n",
    "                new_alpha = new_alpha - int(new_alpha/(2.*np.pi))*(2.*np.pi)\n",
    "\n",
    "                obj = {'name': line[0],\n",
    "                       'image': image_file,\n",
    "                       'xmin': int(float(line[4])),\n",
    "                       'ymin': int(float(line[5])),\n",
    "                       'xmax': int(float(line[6])),\n",
    "                       'ymax': int(float(line[7])),\n",
    "                       'dims': np.array([float(number) for number in line[8:11]]),\n",
    "                       'new_alpha': new_alpha\n",
    "                       }\n",
    "\n",
    "                dims_avg[obj['name']] = dims_cnt[obj['name']] * \\\n",
    "                    dims_avg[obj['name']] + obj['dims']\n",
    "                dims_cnt[obj['name']] += 1\n",
    "                dims_avg[obj['name']] /= dims_cnt[obj['name']]\n",
    "\n",
    "                all_objs.append(obj)\n",
    "\n",
    "    return all_objs, dims_avg\n",
    "\n",
    "\n",
    "all_objs, dims_avg = parse_annotation(label_dir, image_dir)\n",
    "\n",
    "for obj in all_objs:\n",
    "    # Fix dimensions\n",
    "    obj['dims'] = obj['dims'] - dims_avg[obj['name']]\n",
    "\n",
    "    # Fix orientation and confidence for no flip\n",
    "    orientation = np.zeros((BIN, 2))\n",
    "    confidence = np.zeros(BIN)\n",
    "\n",
    "    anchors = compute_anchors(obj['new_alpha'])\n",
    "\n",
    "    for anchor in anchors:\n",
    "        orientation[anchor[0]] = np.array(\n",
    "            [np.cos(anchor[1]), np.sin(anchor[1])])\n",
    "        confidence[anchor[0]] = 1\n",
    "\n",
    "    confidence = confidence / np.sum(confidence)\n",
    "\n",
    "    obj['orient'] = orientation\n",
    "    obj['conf'] = confidence\n",
    "\n",
    "\n",
    "def prepare_input_and_output(train_inst):\n",
    "    # Prepare image patch\n",
    "    xmin = train_inst['xmin']\n",
    "    ymin = train_inst['ymin']\n",
    "    xmax = train_inst['xmax']\n",
    "    ymax = train_inst['ymax']\n",
    "\n",
    "    img = cv2.imread(image_dir + train_inst['image'])\n",
    "    img = copy.deepcopy(img[ymin:ymax+1, xmin:xmax+1]).astype(np.float32)\n",
    "\n",
    "    # re-color the image\n",
    "    img += np.random.randint(-2, 3, img.shape).astype('float32')\n",
    "    t = [np.random.uniform(), np.random.uniform(), np.random.uniform()]\n",
    "    t = np.array(t)\n",
    "\n",
    "    img = img * (1 + t)\n",
    "    img = img / (255 * 2)\n",
    "\n",
    "    # Add rotation (rotate between -20 and 20 degrees)\n",
    "    angle = np.random.uniform(-20, 20)\n",
    "    M = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Add scaling\n",
    "    scale_factor = np.random.uniform(0.8, 1.2)\n",
    "    img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Update position and dimensions according to scaling\n",
    "    train_inst['xmin'] *= scale_factor\n",
    "    train_inst['ymin'] *= scale_factor\n",
    "    train_inst['xmax'] *= scale_factor\n",
    "    train_inst['ymax'] *= scale_factor\n",
    "    train_inst['dims'] *= scale_factor\n",
    "\n",
    "    # Compute center and relative position to the center\n",
    "    center = [img.shape[1]/2, img.shape[0]/2]\n",
    "    pos = [(train_inst['xmax']+train_inst['xmin'])/2, (train_inst['ymax']+train_inst['ymin'])/2]\n",
    "    rel_pos = [pos[0]-center[0], pos[1]-center[1]]\n",
    "\n",
    "    # Compute new position after rotation\n",
    "    new_rel_pos = [rel_pos[0]*np.cos(np.deg2rad(angle)) - rel_pos[1]*np.sin(np.deg2rad(angle)),\n",
    "                   rel_pos[0]*np.sin(np.deg2rad(angle)) + rel_pos[1]*np.cos(np.deg2rad(angle))]\n",
    "    new_pos = [new_rel_pos[0]+center[0], new_rel_pos[1]+center[1]]\n",
    "\n",
    "    # Update position\n",
    "    train_inst['xmin'] = new_pos[0] - train_inst['dims'][0] / 2\n",
    "    train_inst['xmax'] = new_pos[0] + train_inst['dims'][0] / 2\n",
    "    train_inst['ymin'] = new_pos[1] - train_inst['dims'][1] / 2\n",
    "    train_inst['ymax'] = new_pos[1] + train_inst['dims'][1] / 2\n",
    "\n",
    "    # Update orientation according to rotation\n",
    "    train_inst['new_alpha'] += np.deg2rad(angle)\n",
    "    train_inst['new_alpha'] %= 2 * np.pi\n",
    "\n",
    "    # Add random cropping\n",
    "    h, w, _ = img.shape\n",
    "    new_h = int(h * np.random.uniform(0.8, 1))\n",
    "    new_w = int(w * np.random.uniform(0.8, 1))\n",
    "    start_x = np.random.randint(0, w - new_w)\n",
    "    start_y = np.random.randint(0, h - new_h)\n",
    "    img = img[start_y:start_y + new_h, start_x:start_x + new_w]\n",
    "\n",
    "    # Update position according to cropping\n",
    "    train_inst['xmin'] -= start_x\n",
    "    train_inst['ymin'] -= start_y\n",
    "    train_inst['xmax'] -= start_x\n",
    "    train_inst['ymax'] -= start_y\n",
    "\n",
    "    # Flip the image\n",
    "    flip = np.random.binomial(1, 0.5)\n",
    "    if flip > 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "        train_inst['new_alpha'] = 2.*np.pi - train_inst['new_alpha']\n",
    "\n",
    "    # Resize the image to standard size\n",
    "    img = cv2.resize(img, (NORM_H, NORM_W))\n",
    "    img = img - np.array([[[103.939, 116.779, 123.68]]])\n",
    "\n",
    "    # Fix orientation and confidence\n",
    "    orientation = np.zeros((BIN, 2))\n",
    "    confidence = np.zeros(BIN)\n",
    "\n",
    "    anchors = compute_anchors(train_inst['new_alpha'])\n",
    "\n",
    "    for anchor in anchors:\n",
    "        orientation[anchor[0]] = np.array(\n",
    "            [np.cos(anchor[1]), np.sin(anchor[1])])\n",
    "        confidence[anchor[0]] = 1\n",
    "\n",
    "    confidence = confidence / np.sum(confidence)\n",
    "\n",
    "    train_inst['orient_flipped'] = orientation\n",
    "    train_inst['conf_flipped'] = confidence\n",
    "\n",
    "    # Fix orientation and confidence\n",
    "    if flip > 0.5:\n",
    "        return img, train_inst['dims'], train_inst['orient_flipped'], train_inst['conf_flipped']\n",
    "    else:\n",
    "        return img, train_inst['dims'], train_inst['orient'], train_inst['conf']\n",
    "\n",
    "\n",
    "def data_gen(all_objs, batch_size):\n",
    "    num_obj = len(all_objs)\n",
    "\n",
    "    keys = list(range(num_obj))\n",
    "    np.random.shuffle(keys)\n",
    "\n",
    "    l_bound = 0\n",
    "    r_bound = batch_size if batch_size < num_obj else num_obj\n",
    "\n",
    "    while True:\n",
    "        if l_bound == r_bound:\n",
    "            l_bound = 0\n",
    "            r_bound = batch_size if batch_size < num_obj else num_obj\n",
    "            np.random.shuffle(keys)\n",
    "\n",
    "        currt_inst = 0\n",
    "        x_batch = np.zeros((r_bound - l_bound, 224, 224, 3))\n",
    "        d_batch = np.zeros((r_bound - l_bound, 3))\n",
    "        o_batch = np.zeros((r_bound - l_bound, BIN, 2))\n",
    "        c_batch = np.zeros((r_bound - l_bound, BIN))\n",
    "\n",
    "        for key in keys[l_bound:r_bound]:\n",
    "            # augment input image and fix object's orientation and confidence\n",
    "            image, dimension, orientation, confidence = prepare_input_and_output(\n",
    "                all_objs[key])\n",
    "\n",
    "            # plt.figure(figsize=(5,5))\n",
    "            # plt.imshow(image/255./2.); plt.show()\n",
    "            # print dimension\n",
    "            # print orientation\n",
    "            # print confidence\n",
    "\n",
    "            x_batch[currt_inst, :] = image\n",
    "            d_batch[currt_inst, :] = dimension\n",
    "            o_batch[currt_inst, :] = orientation\n",
    "            c_batch[currt_inst, :] = confidence\n",
    "\n",
    "            currt_inst += 1\n",
    "\n",
    "        yield x_batch, [d_batch, o_batch, c_batch]\n",
    "\n",
    "        l_bound = r_bound\n",
    "        r_bound = r_bound + batch_size\n",
    "        if r_bound > num_obj:\n",
    "            r_bound = num_obj\n",
    "\n",
    "\n",
    "def l2_normalize(x):\n",
    "    return tf.nn.l2_normalize(x, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the network\n",
    "# Use ResNet or similar more modern architecture\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers.activation import LeakyReLU\n",
    "from keras.layers.convolutional import (Conv2D, Convolution2D, MaxPooling2D,\n",
    "                                        ZeroPadding2D)\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Lambda, Reshape\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from parameters import BIN\n",
    "from preprocessdata import l2_normalize\n",
    "\n",
    "# Load ResNet model, pre-trained on ImageNet; exclude top FC layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False,\n",
    "                      input_shape=(224, 224, 3))\n",
    "\n",
    "# Make base_model layers non-trainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# You can choose to retrain some of the higher layers\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Now add your custom layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Regularization strength\n",
    "reg_strength = 0.01\n",
    "\n",
    "dimension = Dense(512, kernel_regularizer=l2(reg_strength))(x)\n",
    "dimension = LeakyReLU(alpha=0.1)(dimension)\n",
    "dimension = Dropout(0.5)(dimension)\n",
    "dimension = Dense(3)(dimension)\n",
    "dimension = LeakyReLU(alpha=0.1, name='dimension')(dimension)\n",
    "\n",
    "orientation = Dense(256, kernel_regularizer=l2(reg_strength))(x)\n",
    "orientation = LeakyReLU(alpha=0.1)(orientation)\n",
    "orientation = Dropout(0.5)(orientation)\n",
    "orientation = Dense(BIN*2)(orientation)\n",
    "orientation = LeakyReLU(alpha=0.1)(orientation)\n",
    "orientation = Reshape((BIN, -1))(orientation)\n",
    "orientation = Lambda(l2_normalize, name='orientation')(orientation)\n",
    "\n",
    "confidence = Dense(256, kernel_regularizer=l2(reg_strength))(x)\n",
    "confidence = LeakyReLU(alpha=0.1)(confidence)\n",
    "confidence = Dropout(0.5)(confidence)\n",
    "confidence = Dense(BIN, activation='softmax', name='confidence')(confidence)\n",
    "\n",
    "model = Model(base_model.input, outputs=[dimension, orientation, confidence])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from network import model\n",
    "from preprocessdata import all_objs, data_gen\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "def orientation_loss(y_true, y_pred):\n",
    "    # Find number of anchors\n",
    "    anchors = tf.reduce_sum(tf.square(y_true), axis=2)\n",
    "    anchors = tf.greater(anchors, tf.constant(0.5))\n",
    "    anchors = tf.reduce_sum(tf.cast(anchors, tf.float32), 1)\n",
    "\n",
    "    # Define the loss\n",
    "    loss = -(y_true[:, :, 0]*y_pred[:, :, 0] + y_true[:, :, 1]*y_pred[:, :, 1])\n",
    "    loss = tf.reduce_sum(loss, axis=1)\n",
    "    loss = loss / anchors\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the best models during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'weights.hdf5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "# TensorBoard for visualizing training progress\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='../logs/',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False\n",
    ")\n",
    "\n",
    "all_exams = len(all_objs)\n",
    "trv_split = int(0.9*all_exams)\n",
    "batch_size = 8\n",
    "\n",
    "# Shuffle the dataset\n",
    "np.random.shuffle(all_objs)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_gen = data_gen(all_objs[:trv_split], batch_size)\n",
    "valid_gen = data_gen(all_objs[trv_split:all_exams], batch_size)\n",
    "\n",
    "# Calculate the number of batches for training and validation sets\n",
    "train_num = int(np.ceil(trv_split/batch_size))\n",
    "valid_num = int(np.ceil((all_exams - trv_split)/batch_size))\n",
    "\n",
    "minimizer = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam',  # minimizer,\n",
    "              loss={'dimension': 'mean_squared_error',\n",
    "                    'orientation': orientation_loss, 'confidence': 'mean_squared_error'},\n",
    "              loss_weights={'dimension': 1., 'orientation': 1., 'confidence': 1.})\n",
    "model.fit(train_gen, steps_per_epoch=train_num,\n",
    "          epochs=5,  # 500\n",
    "          verbose=1,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps=valid_num,\n",
    "          callbacks=[early_stop, checkpoint, tensorboard],\n",
    "          max_queue_size=3,\n",
    "          workers=1, use_multiprocessing=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from network import model\n",
    "from preprocessdata import all_objs, data_gen\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "def orientation_loss(y_true, y_pred):\n",
    "    # Find number of anchors\n",
    "    anchors = tf.reduce_sum(tf.square(y_true), axis=2)\n",
    "    anchors = tf.greater(anchors, tf.constant(0.5))\n",
    "    anchors = tf.reduce_sum(tf.cast(anchors, tf.float32), 1)\n",
    "\n",
    "    # Define the loss\n",
    "    loss = -(y_true[:, :, 0]*y_pred[:, :, 0] + y_true[:, :, 1]*y_pred[:, :, 1])\n",
    "    loss = tf.reduce_sum(loss, axis=1)\n",
    "    loss = loss / anchors\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the best models during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'weights.hdf5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "# TensorBoard for visualizing training progress\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='../logs/',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False\n",
    ")\n",
    "\n",
    "all_exams = len(all_objs)\n",
    "trv_split = int(0.9*all_exams)\n",
    "batch_size = 8\n",
    "\n",
    "# Shuffle the dataset\n",
    "np.random.shuffle(all_objs)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_gen = data_gen(all_objs[:trv_split], batch_size)\n",
    "valid_gen = data_gen(all_objs[trv_split:all_exams], batch_size)\n",
    "\n",
    "# Calculate the number of batches for training and validation sets\n",
    "train_num = int(np.ceil(trv_split/batch_size))\n",
    "valid_num = int(np.ceil((all_exams - trv_split)/batch_size))\n",
    "\n",
    "minimizer = SGD(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam',  # minimizer,\n",
    "              loss={'dimension': 'mean_squared_error',\n",
    "                    'orientation': orientation_loss, 'confidence': 'mean_squared_error'},\n",
    "              loss_weights={'dimension': 1., 'orientation': 1., 'confidence': 1.})\n",
    "model.fit(train_gen, steps_per_epoch=train_num,\n",
    "          epochs=5,  # 500\n",
    "          verbose=1,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps=valid_num,\n",
    "          callbacks=[early_stop, checkpoint, tensorboard],\n",
    "          max_queue_size=3,\n",
    "          workers=1, use_multiprocessing=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from network import model\n",
    "from parameters import (BATCH_SIZE, BIN, MAX_JIT, NORM_H, NORM_W,\n",
    "                        OVERLAP, VEHICLES, image_dir, label_dir)\n",
    "from preprocessdata import dims_avg\n",
    "\n",
    "model.load_weights('weights.hdf5')\n",
    "image_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/image_00/data/'\n",
    "box2d_loc = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/box_2d/'\n",
    "box3d_loc = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/box_3d/'\n",
    "\n",
    "all_image = sorted(os.listdir(image_dir))\n",
    "# np.random.shuffle(all_image)\n",
    "\n",
    "for f in all_image:\n",
    "    image_file = image_dir + f\n",
    "    box2d_file = box2d_loc + f.replace('png', 'txt')\n",
    "    box3d_file = box3d_loc + f.replace('png', 'txt')\n",
    "\n",
    "    with open(box3d_file, 'w') as box3d:\n",
    "        img = cv2.imread(image_file)\n",
    "        img = img.astype(np.float32, copy=False)\n",
    "        open(box2d_file, 'w')\n",
    "        for line in open(box2d_file):\n",
    "            line = line.strip().split(' ')\n",
    "            truncated = np.abs(float(line[1]))\n",
    "            occluded = np.abs(float(line[2]))\n",
    "\n",
    "            obj = {'xmin': int(float(line[4])),\n",
    "                   'ymin': int(float(line[5])),\n",
    "                   'xmax': int(float(line[6])),\n",
    "                   'ymax': int(float(line[7])),\n",
    "                   }\n",
    "\n",
    "            patch = img[obj['ymin']:obj['ymax'], obj['xmin']:obj['xmax']]\n",
    "            patch = cv2.resize(patch, (NORM_H, NORM_W))\n",
    "            patch = patch - np.array([[[103.939, 116.779, 123.68]]])\n",
    "            patch = np.expand_dims(patch, 0)\n",
    "\n",
    "            prediction = model.predict(patch)\n",
    "\n",
    "            # Transform regressed angle\n",
    "            max_anc = np.argmax(prediction[2][0])\n",
    "            anchors = prediction[1][0][max_anc]\n",
    "\n",
    "            if anchors[1] > 0:\n",
    "                angle_offset = np.arccos(anchors[0])\n",
    "            else:\n",
    "                angle_offset = -np.arccos(anchors[0])\n",
    "\n",
    "            wedge = 2.*np.pi/BIN\n",
    "            angle_offset = angle_offset + max_anc*wedge\n",
    "            angle_offset = angle_offset % (2.*np.pi)\n",
    "\n",
    "            angle_offset = angle_offset - np.pi/2\n",
    "            if angle_offset > np.pi:\n",
    "                angle_offset = angle_offset - (2.*np.pi)\n",
    "\n",
    "            line[3] = str(angle_offset)\n",
    "\n",
    "            # Transform regressed dimension\n",
    "            dims = dims_avg['Car'] + prediction[0][0]\n",
    "\n",
    "            line = line + list(dims)\n",
    "\n",
    "            # Write regressed 3D dim and oritent to file\n",
    "            line = ' '.join([str(item) for item in line]) + '/n'\n",
    "            box3d.write(line)\n",
    "\n",
    "            cv2.rectangle(img, (obj['xmin'], obj['ymin']),\n",
    "                          (obj['xmax'], obj['ymax']), (255, 0, 0), 3)\n",
    "\n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.imshow(img/255.)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import parseTrackletXML as xmlParser\n",
    "\n",
    "label_path = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/label_00/'\n",
    "image_path = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/image_00/data/'\n",
    "# calib_path = '/home/husky/data/kitti_object/data_object_calib/training/calib/'\n",
    "\n",
    "predi_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/predict_00/'\n",
    "image_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/image_00/data/'\n",
    "calib_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/calib_00/'\n",
    "\n",
    "box2d_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/box_2d/'\n",
    "box3d_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/box_3d/'\n",
    "label_dir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/2011_09_26_drive_0014_sync/label_00/'\n",
    "\n",
    "dataset = [name.split('.')[0] for name in sorted(os.listdir(predi_dir))]\n",
    "video_out = 'E:/workspace/2dto3d/data/kitti_3D.avi'\n",
    "video_writer = None\n",
    "\n",
    "all_image = sorted(os.listdir(image_dir))\n",
    "# np.random.shuffle(all_image)\n",
    "\n",
    "for f in all_image:\n",
    "    image_file = image_dir + f\n",
    "    calib_file = calib_dir + f.replace('png', 'txt')\n",
    "    predi_file = predi_dir + f.replace('png', 'txt')\n",
    "\n",
    "    # read calibration data\n",
    "    open(calib_file, 'w')\n",
    "    open(predi_file, 'w')\n",
    "    for line in open(calib_file):\n",
    "        if 'P2:' in line:\n",
    "            cam_to_img = line.strip().split(' ')\n",
    "            cam_to_img = np.asarray([float(number)\n",
    "                                    for number in cam_to_img[1:]])\n",
    "            cam_to_img = np.reshape(cam_to_img, (3, 4))\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    cars = []\n",
    "\n",
    "    if video_writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        video_writer = cv2.VideoWriter(video_out, fourcc, 25.0, (1242, 375))\n",
    "\n",
    "    # Draw 3D Bounding Box\n",
    "    for line in open(predi_file):\n",
    "        line = line.strip().split(' ')\n",
    "\n",
    "        dims = np.asarray([float(number) for number in line[8:11]])\n",
    "        center = np.asarray([float(number) for number in line[11:14]])\n",
    "        rot_y = float(line[3]) + np.arctan(center[0] /\n",
    "                                           center[2])  # float(line[14])\n",
    "\n",
    "        box_3d = []\n",
    "\n",
    "        for i in [1, -1]:\n",
    "            for j in [1, -1]:\n",
    "                for k in [0, 1]:\n",
    "                    point = np.copy(center)\n",
    "                    point[0] = center[0] + i * dims[1]/2 * \\\n",
    "                        np.cos(-rot_y+np.pi/2) + (j*i) * \\\n",
    "                        dims[2]/2 * np.cos(-rot_y)\n",
    "                    point[2] = center[2] + i * dims[1]/2 * \\\n",
    "                        np.sin(-rot_y+np.pi/2) + (j*i) * \\\n",
    "                        dims[2]/2 * np.sin(-rot_y)\n",
    "                    point[1] = center[1] - k * dims[0]\n",
    "\n",
    "                    point = np.append(point, 1)\n",
    "                    point = np.dot(cam_to_img, point)\n",
    "                    point = point[:2]/point[2]\n",
    "                    point = point.astype(np.int16)\n",
    "                    box_3d.append(point)\n",
    "\n",
    "        for i in range(4):\n",
    "            point_1_ = box_3d[2*i]\n",
    "            point_2_ = box_3d[2*i+1]\n",
    "            cv2.line(image, (point_1_[0], point_1_[1]),\n",
    "                     (point_2_[0], point_2_[1]), (0, 255, 0), 2)\n",
    "\n",
    "        for i in range(8):\n",
    "            point_1_ = box_3d[i]\n",
    "            point_2_ = box_3d[(i+2) % 8]\n",
    "            cv2.line(image, (point_1_[0], point_1_[1]),\n",
    "                     (point_2_[0], point_2_[1]), (0, 255, 0), 2)\n",
    "\n",
    "    video_writer.write(np.uint8(image))\n",
    "\n",
    "all_image = sorted(os.listdir(image_dir))\n",
    "# np.random.shuffle(all_image)\n",
    "\n",
    "for f in all_image:\n",
    "    image_file = image_dir + f\n",
    "    box2d_file = box2d_dir + f.replace('png', 'txt')\n",
    "    box3d_file = box3d_dir + f.replace('png', 'txt')\n",
    "    label_file = label_dir + f.replace('png', 'txt')\n",
    "    calib_file = calib_dir + f.replace('png', 'txt')\n",
    "    predi_file = predi_dir + f.replace('png', 'txt')\n",
    "\n",
    "    open(label_file, 'w')\n",
    "\n",
    "    with open(predi_file, 'w') as prediction:\n",
    "        # Construct list of all candidate centers\n",
    "        centers_2d = []\n",
    "        centers_3d = []\n",
    "\n",
    "        for line in open(calib_file):\n",
    "            if 'P2:' in line:\n",
    "                cam_to_img = line.strip().split(' ')\n",
    "                cam_to_img = np.asarray([float(number)\n",
    "                                        for number in cam_to_img[1:]])\n",
    "                cam_to_img = np.reshape(cam_to_img, (3, 4))\n",
    "\n",
    "        for line in open(label_file):\n",
    "            line = line.strip().split(' ')\n",
    "\n",
    "            center = np.asarray([float(number) for number in line[11:14]])\n",
    "            center = np.append(center, 1)\n",
    "            center = np.dot(cam_to_img, center)\n",
    "            center = center[:2]/center[2]\n",
    "            center = center.astype(np.int16)\n",
    "\n",
    "            centers_2d.append(center)\n",
    "            centers_3d.append(np.asarray([float(number)\n",
    "                              for number in line[11:14]]))\n",
    "\n",
    "        # Find the nearest centres among the candidates\n",
    "        for line in open(box3d_file):\n",
    "            line = line.strip().split(' ')\n",
    "\n",
    "            obj = {'xmin': int(float(line[4])),\n",
    "                   'ymin': int(float(line[5])),\n",
    "                   'xmax': int(float(line[6])),\n",
    "                   'ymax': int(float(line[7])), }\n",
    "\n",
    "            center = np.asarray(\n",
    "                [(obj['xmin']+obj['xmax'])/2., (obj['ymin'] + obj['ymax'])/2.])\n",
    "\n",
    "            nearest_index = -1\n",
    "            last_distance = 1000000000.\n",
    "\n",
    "            for i in range(len(centers_2d)):\n",
    "                candidate = centers_2d[i]\n",
    "                distance = np.sum(np.square(center - candidate))\n",
    "\n",
    "                if distance < 1000 and distance < last_distance:\n",
    "                    nearest_index = i\n",
    "                    last_distance = distance\n",
    "\n",
    "            if nearest_index > -1:\n",
    "                line += list(centers_3d[nearest_index])\n",
    "                del centers_2d[nearest_index]\n",
    "                del centers_3d[nearest_index]\n",
    "\n",
    "                # Write regressed 3D dim and oritent to file\n",
    "                line = ' '.join([str(item) for item in line]) + '\\n'\n",
    "                prediction.write(line)\n",
    "kittiDir = 'E:/workspace/2dto3d/data/2011_09_26_drive_0014_sync/2011_09_26/'\n",
    "drive = '2011_09_26_drive_0014_sync/'\n",
    "\n",
    "label_dir = kittiDir + drive + 'label_00/'\n",
    "image_dir = kittiDir + drive + 'image_00/data/'\n",
    "calib_dir = kittiDir + drive + 'calib_00/'\n",
    "\n",
    "# FIGURE OUT THE LABELS\n",
    "os.system('rm ' + label_dir + '*')\n",
    "os.system('rm ' + calib_dir + '*')\n",
    "\n",
    "# Read transformation matrices\n",
    "for line in open(kittiDir + drive + 'calib_velo_to_cam.txt'):\n",
    "    if 'R:' in line:\n",
    "        R = line.strip().split(' ')\n",
    "        R = np.asarray([float(number) for number in R[1:]])\n",
    "        R = np.reshape(R, (3, 3))\n",
    "\n",
    "    if 'T:' in line:\n",
    "        T = line.strip().split(' ')\n",
    "        T = np.asarray([float(number) for number in T[1:]])\n",
    "        T = np.reshape(T, (3, 1))\n",
    "\n",
    "for line in open(kittiDir + drive + 'calib_cam_to_cam.txt'):\n",
    "    if 'R_rect_00:' in line:\n",
    "        R0_rect = line.strip().split(' ')\n",
    "        R0_rect = np.asarray([float(number) for number in R0_rect[1:]])\n",
    "        R0_rect = np.reshape(R0_rect, (3, 3))\n",
    "\n",
    "R0_rect = np.append(R0_rect, np.zeros((3, 1)), axis=1)\n",
    "R0_rect = np.append(R0_rect, np.zeros((1, 4)), axis=0)\n",
    "R0_rect[-1, -1] = 1\n",
    "\n",
    "Tr_velo_to_cam = np.concatenate([R, T], axis=1)\n",
    "Tr_velo_to_cam = np.append(Tr_velo_to_cam, np.zeros((1, 4)), axis=0)\n",
    "Tr_velo_to_cam[-1, -1] = 1\n",
    "\n",
    "transform = np.dot(R0_rect, Tr_velo_to_cam)\n",
    "\n",
    "# print Tr_velo_to_cam\n",
    "# print R0_rect\n",
    "# print transform\n",
    "\n",
    "# Read the tracklets\n",
    "for trackletObj in xmlParser.parseXML(kittiDir + drive + 'tracklet_labels.xml'):\n",
    "    for translation, rotation, state, occlusion, truncation, amtOcclusion, amtBorders, absoluteFrameNumber in trackletObj:\n",
    "        label_file = label_dir + str(absoluteFrameNumber).zfill(10) + '.txt'\n",
    "\n",
    "        translation = np.append(translation, 1)\n",
    "        translation = np.dot(transform, translation)\n",
    "        translation = translation[:3]/translation[3]\n",
    "\n",
    "        with open(label_file, 'a') as file_writer:\n",
    "            line = [trackletObj.objectType] + [0, 0, rotation[2]] + [0, 0, 0,\n",
    "                                                                     0] + list(trackletObj.size) + list(translation) + [rotation[2]]\n",
    "            line = ' '.join([str(item) for item in line]) + '\\n'\n",
    "            file_writer.write(line)\n",
    "\n",
    "# FIGURE OUT THE CALIBRATION\n",
    "for line in open(kittiDir + drive + 'calib_cam_to_cam.txt'):\n",
    "    if 'P_rect_02' in line:\n",
    "        line_P2 = line.replace('P_rect_02', 'P2')\n",
    "        print(line_P2)\n",
    "\n",
    "for image in os.listdir(image_dir):\n",
    "    label_file = label_dir + image.split('.')[0] + '.txt'\n",
    "    calib_file = calib_dir + image.split('.')[0] + '.txt'\n",
    "\n",
    "    # Create calib files\n",
    "    with open(calib_file, 'w') as file_writer:\n",
    "        file_writer.write(line_P2)\n",
    "\n",
    "    # Fix missing lables\n",
    "    with open(label_file, 'a') as file_writer:\n",
    "        file_writer.write('')\n",
    "\n",
    "all_image = sorted(os.listdir(image_dir))\n",
    "# np.random.shuffle(all_image)\n",
    "\n",
    "for f in all_image:\n",
    "    image_file = image_dir + f\n",
    "    calib_file = calib_dir + f.replace('png', 'txt')\n",
    "    predi_file = predi_dir + f.replace('png', 'txt')\n",
    "\n",
    "    # read calibration data\n",
    "    for line in open(calib_file):\n",
    "        if 'P2:' in line:\n",
    "            cam_to_img = line.strip().split(' ')\n",
    "            cam_to_img = np.asarray([float(number)\n",
    "                                    for number in cam_to_img[1:]])\n",
    "            cam_to_img = np.reshape(cam_to_img, (3, 4))\n",
    "\n",
    "        # if 'R0_rect:' in line:\n",
    "        #    R0_rect = line.strip().split(' ')\n",
    "        #    R0_rect = np.asarray([float(number) for number in R0_rect[1:]])\n",
    "        #    R0_rect = np.reshape(R0_rect, (3,3))\n",
    "\n",
    "        # if 'Tr_velo_to_cam:' in line:\n",
    "        #    Tr_velo_to_cam = line.strip().split(' ')\n",
    "        #    Tr_velo_to_cam = np.asarray([float(number) for number in Tr_velo_to_cam[1:]])\n",
    "        #    Tr_velo_to_cam = np.reshape(Tr_velo_to_cam, (3,4))\n",
    "\n",
    "    # R0_rect = np.append(R0_rect, np.zeros((3,1)), axis=1)\n",
    "    # R0_rect = np.append(R0_rect, np.zeros((1,4)), axis=0)\n",
    "    # R0_rect[-1,-1] = 1\n",
    "\n",
    "    # Tr_velo_to_cam = np.append(Tr_velo_to_cam, np.zeros((1,4)), axis=0)\n",
    "    # Tr_velo_to_cam[-1,-1] = 1\n",
    "\n",
    "# draw 2D boxes and 3D boxes\n",
    "index = 11\n",
    "image = cv2.imread(image_path + dataset[index] + '.png')\n",
    "cars = []\n",
    "\n",
    "for line in open(label_path + dataset[index] + '.txt').readlines():\n",
    "    line = line.strip().split(' ')\n",
    "\n",
    "    if 'Car' in line[0]:\n",
    "        # Draw 2D Bounding Box\n",
    "        x_min, y_min, x_max, y_max = [\n",
    "            int(float(number)) for number in line[4:8]]\n",
    "        # cv2.rectangle(image, (x_min,y_min), (x_max,y_max), (255,255,0), 3)\n",
    "\n",
    "        # Draw 3D Bounding Box\n",
    "        dims = np.asarray([float(number) for number in line[8:11]])\n",
    "        center = np.asarray([float(number) for number in line[11:14]])\n",
    "\n",
    "        if np.abs(float(line[3])) < 0.01:\n",
    "            continue\n",
    "        print(line[3], center)\n",
    "\n",
    "        rot_y = float(line[3]) + np.arctan(center[0] /\n",
    "                                           center[2])  # float(line[14])\n",
    "\n",
    "        box_3d = []\n",
    "\n",
    "        for i in [1, -1]:\n",
    "            for j in [1, -1]:\n",
    "                for k in [0, 1]:\n",
    "                    point = np.copy(center)\n",
    "                    point[0] = center[0] + i * dims[1]/2 * \\\n",
    "                        np.cos(-rot_y+np.pi/2) + (j*i) * \\\n",
    "                        dims[2]/2 * np.cos(-rot_y)\n",
    "                    point[2] = center[2] + i * dims[1]/2 * \\\n",
    "                        np.sin(-rot_y+np.pi/2) + (j*i) * \\\n",
    "                        dims[2]/2 * np.sin(-rot_y)\n",
    "                    point[1] = center[1] - k * dims[0]\n",
    "\n",
    "                    point = np.append(point, 1)\n",
    "                    point = np.dot(cam_to_img, point)\n",
    "                    point = point[:2]/point[2]\n",
    "                    point = point.astype(np.int16)\n",
    "                    box_3d.append(point)\n",
    "\n",
    "        for i in range(4):\n",
    "            point_1_ = box_3d[2*i]\n",
    "            point_2_ = box_3d[2*i+1]\n",
    "            cv2.line(image, (point_1_[0], point_1_[1]),\n",
    "                     (point_2_[0], point_2_[1]), (255, 0, 0), 3)\n",
    "\n",
    "        for i in range(8):\n",
    "            point_1_ = box_3d[i]\n",
    "            point_2_ = box_3d[(i+2) % 8]\n",
    "            cv2.line(image, (point_1_[0], point_1_[1]),\n",
    "                     (point_2_[0], point_2_[1]), (255, 0, 0), 3)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
